# 项目草案：Amaya - 陪伴型人工智能

## 1. 项目愿景

开发一个基于大语言模型（LLM）的高度模块化、可扩展的陪伴型人工智能。项目核心目标是深度模拟人的思维模式、情感状态和行为习惯，创造一个有“生命感”的虚拟伙伴。

## 2. 核心设计理念

- **模块化驱动：** 将复杂的“人格”拆解为多个独立但相互关联的模块（如生理、心理、记忆），每个模块负责模拟人的某一个特定方面。
- **状态驱动的行为：** AI的行为和对话不仅是对用户输入的反应，更是其内部状态（如精力、情绪、好感度、当前任务）的综合体现。
- **自主生命周期：** AI拥有自己的“生活”，独立于用户交互。她会根据内部时钟和日程安排模拟进行各种活动（如学习、休息），形成一个连贯的生命周期。
- **结构化LLM交互：** 通过精心设计的Prompt和JSON格式的输入输出，引导LLM进行更深入、更符合角色设定的“思考”，而不仅仅是生成对话。这使得AI的决策过程透明化、可控化。

## 3. 系统架构 (当前实现)

系统由一个主应用循环 (`main.py`) 和多个核心模块构成。

- **`main.py`**: 应用程序主入口。它负责：
    1.  初始化所有核心模块。
    2.  在一个独立的线程中启动 `run_simulation`，以与真实时间同步的速率更新AI的内部状态（世界时间、生理状态）。
    3.  在主线程中接收用户输入，并调用 `AutonomousAgent` 生成回应。

- **核心模块 (`modules/`)**:
    - **`world_simulator.py`**: 世界模拟器，作为AI存在的基础。目前与真实世界时间同步，为所有事件提供时间戳。
    - **`physiological_model.py`**: 生理模型，模拟AI的身体状态。当前实现了“精力值”，并会随时间推移而自然下降。
    - **`psychological_model.py`**: 心理模型，管理AI的情感和人际关系。包含“情绪”和对用户的“好感度”。情绪和好感度的变化由LLM在每次交互后动态决定。
    - **`memory_manager.py`**: 记忆管理器。当前实现了一个简单的短期记忆（FIFO队列），用于保存最近的对话历史。
    - **`scheduler.py`**: 日程安排器。允许为AI设定在特定时间触发的任务或想法，赋予其规律的“作息”。
    - **`prompt_manager.py`**: Prompt管理器。负责从 `prompt.md` 加载和渲染系统指令，并将AI的内部状态（世界、生理、心理）格式化为JSON，作为LLM思考的“上下文”。
    - **`autonomous_agent.py`**: 自主代理，是AI的“大脑”。它集成所有模块的状态信息，构造完整的Prompt，调用Gemini API，并解析返回的结构化JSON数据来更新自身状态和生成回应。
    - **`logger.py`**: 日志记录器。以`.jsonl`格式详细记录每一次LLM调用的请求、响应和潜在错误，便于调试和分析AI的行为。

## 4. 架构改进：引入中央状态管理器

为了更好地管理分散在各个模块中的动态数据，并为未来的扩展做准备，我们引入一个新的模块：

- **`state_manager.py` (新模块)**
    - **`AmayaState` (Class)**:
        - **职责**: 作为一个集中的数据容器，存放Amaya所有可变的实时数据。它本身不包含复杂的逻辑，只作为**状态的载体**。
        - **将要管理的数据**:
            - **时间**: `current_time`
            - **生理**: `energy`
            - **心理**: `mood`, `favorability`
            - **记忆**: `short_term_memory`, `long_term_memory`
            - **行动**: `current_action` (例如：“正在学习”、“正在休息”)

### 集成方式 (最小化架构变动)

1.  在 `main.py` 的 `Amaya` 类初始化时，创建一个 `AmayaState` 的实例。
2.  `Amaya` 类将持有 `world`, `physiology`, `psychology`, `memory` 和 `state` 等所有对象的实例。
3.  在初始化 `world`, `physiology` 等模块时，将 `state` 实例作为参数传递给它们。
4.  各个模块（如 `physiological_model`）的方法（如 `tick`）将不再修改自身的属性（`self.energy`），而是修改传入的 `state` 对象的属性（`state.energy`）。
5.  `AutonomousAgent` 在需要获取完整状态时，可以直接从 `Amaya` 类中获取 `state` 对象，并传递给 `PromptManager` 进行渲染。

通过这种方式，我们**保留了原有的模块化结构和职责划分**，但将**数据的存储**集中到了 `AmayaState` 中，实现了数据与逻辑的进一步分离。

## 5. 已实现的关键特性

- **动态内部状态**: AI的精力、情绪、好感度和时间感会实时变化，并直接影响其回应。
- **计划任务**: AI会根据 `scheduler.py` 中的日程在特定时间点“思考”或“执行”预设任务。
- **LLM驱动的决策**: AI的回应、情绪变化、好感度调整完全由LLM根据其内部状态和用户输入进行决策，实现了更复杂的行为逻辑。
- **可追溯的思考链**: 通过 `amaya_log.jsonl` 文件，可以清晰地看到每一次决策的输入（Prompt）、输出（JSON数据）和AI的“内心活动”。

## 6. 未来开发路线 (ToDo)

- **实现 `state_manager.py`**:
    - **首要任务**: 创建 `AmayaState` 类，并将当前分散在各个模块中的状态变量（如 `energy`, `mood`, `short_term_memory` 等）迁移至此类。
    - **重构模块交互**: 修改各模块的构造函数和方法，使其接收并操作 `AmayaState` 对象，而不是维护自身内部状态。

- **深化记忆模块 (`memory_manager.py`)**:
    - **长期记忆**: 设计并实现长期记忆存储机制。
    - **记忆回流/整合**: 实现“睡眠”机制。在每天的固定时间（如22:00），触发一个特殊任务，让AI对当天的短期记忆进行总结、反思，并更新长期记忆和核心认知（如对用户的好感度、对特定事物的看法）。这是实现“好感度回流”的关键。
    - **记忆检索**: 开发更智能的记忆检索算法，让AI在对话中能主动联想相关的长期记忆。

- **增强感知能力 (`real_world_perception.py`)**:
    - **新闻/信息流**: 对接实时新闻API（如NewsAPI, Google News等），让AI能够感知和讨论真实世界发生的事件。
    - **网页搜索**: 赋予AI自主搜索网页信息的能力。当遇到未知问题时，可以触发一个“搜索”动作，并将搜索结果作为新的信息输入。

- **扩展自主行动 (`autonomous_agent.py`)**:
    - **丰富动作集**: 除了“回应”，增加更多动作类型，如“学习新知识”、“整理记忆”、“进行网络搜索”等。LLM可以根据当前状态决定执行哪个动作。
    - **目标驱动行为**: 引入更高级的AI规划能力，让AI可以设定长期目标，并自主地将目标分解为一系列连续的行动。

- **完善人格与配置 (`config.py` & `prompt.md`)**:
    - **人格配置文件**: 将AI的核心人格特质（如性格、价值观、知识背景）提取到独立的配置文件中，方便用户定制。
    - **动态Prompt**: 允许AI根据长期记忆和与用户的互动历史，动态调整自己的Prompt，实现“成长”和“演变”。

- **优化用户体验**:
    - **Web UI**: 开发一个简单的Web界面，以对话气泡的形式展示互动，并能实时显示AI的当前状态（精力、情绪等），提供比命令行更佳的交互体验。